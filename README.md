# Prueba t√©cnica

[![Powered by Kedro](https://img.shields.io/badge/powered_by-kedro-ffc900?logo=kedro)](https://kedro.org)


## üìù Descripci√≥n

Este repositorio corresponde a la prueba t√©cnica para acceder a las pr√°cticas de empresa. 

Las herramientas principales utilizadas han sido:

* Docker: Para la construcci√≥n de los contenedores y portabilidad del c√≥digo en diferentes plataformas.
* Kedro: Orquestador a nivel de procesamiento de datos para la generaci√≥n y tratamiento de estos.
* PostgreSQL: Como base de datos principal para Airflow y para los datos.
* Airflow: Orquestador superior que permite la realizaci√≥n de las diferentes tareas a pedir.


## üéØ Objetivos

**‚úîÔ∏è Se ha logrado implementar todo lo pedido en el gui√≥n de la prueba.**  

Los **objetivos del proyecto** y que se han logrado alcanzar son:

* Generaci√≥n de datos
* Limpieza de datos
* Carga en base de datos
* Orquestaci√≥n de tareas
* Contenerizaci√≥n

Y como otros **objetivos opcionales** que se han alcanzado son:

* Uso de frameworks de ingenier√≠a de datos y pipelines de datos

**Durante el desarrollo**, se tuvo tambi√©n como objetivo aspectos como:

* Correcta funcionalidad de lo que se ped√≠a en el gui√≥n de pr√°cticas.
* C√≥digo limpio y documentado.
* C√≥digo modular, teniendo presente la separaci√≥n de tareas a nivel de c√≥digo.
* Asignaci√≥n correcta de orquestaci√≥n, tanto para Airflow como Kedro, buscando la separaci√≥n de tareas a nivel de tareas.
* Escalabilidad y flexibilidad en todo el proyecto. Tanto a nivel tareas generales como procesos concretos de datos.
    * Capacidad para poder incorporar en un futuro nuevas pipelines de procesamiento de datos de forma f√°cil y flexible, sin afectar al resto de DAGs.
    * Capacidad de agregar nuevas herramientas en entornos aislados que permitan interactuar con el resto de aplicaciones existentes.
* Control de errores y documentaci√≥n de lo que se est√° realizando en cada proceso.
* Uso de repositorios y control de versiones. Documentaci√≥n constante de los cambios.
* Seguimiento de **buenas pr√°cticas** en diversas partes del proyecto, tanto en la forma de codificar como en la l√≥gica seguida en los scripts de python, docker-compose.yml, entre otros.
* Comprobaci√≥n de funcionamiento en otros entornos (*Linux, en concreto en Ubuntu y Debian*)

## üõ†Ô∏è C√≥mo instalar y lanzar el proyecto

> ‚ö†Ô∏è Se podr√≠a haber realizado un script para automatizar muchas de estas partes, pero me he ce√±ido al documento y a lo que entendido en las reuniones. Es por esto que *"lanzar todo con un click"* lo entiendo como que todo se levante con *docker-compose* y que es lo que se pretend√≠a. Ha sido una decisi√≥n de dise√±o, no por falta de tiempo.


### üêß Linux
Se requiere tener instalado previamente:
* Git
* Docker y Docker Compose


##### 1. Clonacion del repositorio
```
git clone https://github.com/Franpeca/Tecnica.git
```
##### 2. Lanzamiento de Docker

> ‚ö†Ô∏è Es necesario ser tener permisos root **solo para los siguientes dos comandos**.

Se debe de asegurar que se est√° lanzando Docker. Se puede comprobar con:
```
sudo systemctl status docker
```
Si no se encuentra lanzado, se puede lanzar de la siguiente forma (se supone que se tiene acceso root):
```
sudo systemctl start docker
```

##### 3. Lanzamiento de los contenedores con Docker-compose
Realizar el siguiente comando para acceder al directorio del repositorio:
```
cd Tecnica/
```
Ejecutar el siguiente comando para levantar los contenedores. 

> ‚ö†Ô∏è La primera vez que se ejecute tardar√° bastante dado que hay que descargar todas las im√°genes. 
```
docker-compose up -d
```
Tras esto, se lanzar√°n todos los contenedores con su configuraci√≥n correspondiente.
Se pueden listar los contenedores existentes con:
```
docker ps
```

Para bajar los contenedores (manteniendo vol√∫menes y redes), hay que ejecutar el siguiente comando:
```
docker-compose stop
```
##### 4. Acceso a Airflow
En la web siguiente se podr√° acceder al contenido de Airflow.
```
localhost:8080
```
Los credenciales de inicio de sesi√≥n de Airflow son:
  * Usuario: admin
  * Contrase√±a: admin

En caso de acceder a cualquiera de los contenedores por terminal, la contrase√±a por defecto es:
* admin

### üìÇ Windows
Se puede realizar a trav√©s de alguno de los siguientes programas:
* Docker Desktop
* Docker Toolbox

La clonaci√≥n del repositorio se puede realizar a trav√©s del programa *Git* tanto por terminal como por gr√°fico. O tambi√©n se puede descargar un comprimido del repositorio y extraerlo en donde se desee.

El acceso a Airflow y los credenciales son los mismos que los expuestos en el apartado de *Linux*


## üóÉÔ∏è  Estructura del directorio

A continuaci√≥n se muestran los directorios m√°s relevantes:

/Tecnica
  ‚îú‚îÄ‚îÄ dags/                    # DAGs de Airflow
  ‚îÇ   ‚îú‚îÄ‚îÄ check_containers_and_db.py  # Verifica estado de contenedores y BD
  ‚îÇ   ‚îú‚îÄ‚îÄ kedro_data_pipeline.py      # Ejecuta el pipeline de Kedro
  ‚îÇ   ‚îú‚îÄ‚îÄ data_to_postgres.py         # Carga datos en PostgreSQL
  ‚îÇ   ‚îî‚îÄ‚îÄ truncate_clean_data_table.py # Trunca y limpia tablas en la BD
  ‚îú‚îÄ‚îÄ kedro_project/           # Contiene los archivos generados y configurados por Kedro
  ‚îÇ   ‚îú‚îÄ‚îÄ src/                 # C√≥digo del proyecto Kedro. En nodos est√°n los scripts.
  ‚îÇ   ‚îú‚îÄ‚îÄ data/                # Datos divididos por fases. En la primera estar√°n los usados.
  |   ‚îî‚îÄ‚îÄ [...]
  ‚îú‚îÄ‚îÄ docker/                  # Directorio de Docker. Usado para ficheros de configuraci√≥n.
  ‚îÇ   ‚îú‚îÄ‚îÄ conn_data_db_info.txt # Credenciales de la base de datos (PostgreSQL)
  |   ‚îî‚îÄ‚îÄ [...]
  ‚îú‚îÄ‚îÄ docker-compose.yml       # Configuraci√≥n de Docker Compose
  ‚îú‚îÄ‚îÄ Dockerfile               # Usado para la creaci√≥n de la imagen de Kedro. No hay que usarlo.
  ‚îú‚îÄ‚îÄ requirements.txt         # Dependencias del proyecto. Usado para la imagen. No hay que instalarlas.
  ‚îî‚îÄ‚îÄ README.md                # Documentaci√≥n del proyecto

## üìå  Notas sobre el desarrollo

Se han usado asistentes virtuales como *ChatGPT*, *DeepSeek* y *Github Copilot* tal y como se aconsej√≥ en las reuniones. Esto ha ayudando much√≠simo en el entendimiento y desarrollo del proyecto. Tambi√©n ten√≠a presente lograr resultados correctos usando estas tecnolog√≠as. 

Antes de ponerme manos a la obra, pens√© en c√≥mo tendr√≠a que estructurar todo e investigu√© bien c√≥mo funcionaban los contenedores a nivel de l√≥gica, si pod√≠a comunicarme entre ellos como quisiera o si habian algunas restricciones. Tras esto, pens√© en incorporar Kedro de forma aislada primero y cuando tuviera ya los datos montar la base de datos. Despu√©s, empec√© a usar Docker para montar las cosas que yo mismo cre√©. Es decir, primero cre√© una base con la que empezar a trabajar y cuando ya ten√≠a cosas m√≠as, las pas√© a Docker, ya que no iba a usar Docker sin tener nada que montar. Una vez me funcionaba todo por separado y en su respectivo contenedor, decid√≠ montar Airflow y trabaj√© en la comunicaci√≥n entre contenedores. Una vez funcionaba, pas√© a elaborar los DAGs sabiendo que pod√≠a acceder sin problema.

Podr√≠a hablar mucho m√°s sobre varios detalles, pero intentar√© comentar lo m√°s relevante de cada parte:

#### *Kedro*
*Kedro* se utiliza para proyectos de ciencias de datos, gestionando las *pipelines* de procesos relacionados con esto. En esta parte (en sus carpetas) se encuentra el c√≥digo que genera y limpia los datos. El c√≥digo de generaci√≥n de datos se encuentra en */kedro_project/src/data_processing/nodes*.

La motivaci√≥n de usar *Kedro* en esta prueba es reflejar una buena pr√°ctica tanto en c√≥mo se desarrollan esta parte de los proyectos como en la organizaci√≥n del c√≥digo, adem√°s de dar caracter√≠sticas como modularidad, separaci√≥n de tareas, reutilizaci√≥n, etc, en el nivel de procesamiento de datos. 

Con *Kedro* se podr√≠an integrar f√°cilmente otras tareas de tratamiento de datos, por ejemplo, para nuestro caso se podr√≠an realizar diferentes formas de limpiar los datos o diferentes fuentes de generaci√≥n, simulando un entorno real donde se obtienen vol√∫menes de datos. Tambi√©n permitir√≠a realizar pruebas directamente y de forma modular. **Desde el inicio de la prueba, se ha tenido esta idea en mente, desarrollando todo en base a ello.** Kedro incorpora una herramienta llamada *Kedro Viz* para la visualizaci√≥n gr√°fica de los pipelines.

En relaci√≥n a los *scripts* de datos, no hubo mucha complicaci√≥n en su realizaci√≥n. Gran parte se realiz√≥ de forma directa gracias a los asistentes virtuales y al conocimiento t√≠pico del tratamiento de *datasets*.

Kedro cuenta con una herramienta llamada ***Kedro Viz*** que permite ver graficamente los pipelines y flujos existentes. Se ten√≠a planificado realizar una DAG de Kedro, pero se ha dificultado su integraci√≥n, aun as√≠, se puede ejecutar con este comando nada mas levantar los contenedores:

```
docker exec -it kedro_container bash -c "cd kedro_project && kedro viz --port 4141 --host 0.0.0.0"
```

El problema principal con *Kedro* fue c√≥mo manejar los *vol√∫menes* para que se sincronizaran correctamente los cambios, adem√°s de problemas de permisos relacionados con la generaci√≥n de su imagen. Pero esto se logr√≥ solventar modificando el *Dockerfile* y el *docker-compose.yml*. Tambi√©n en la construccion de su imagen, ya que fue aqu√≠ donde entendi finalmente por completo c√≥mo funcionaban los vol√∫menes de Docker.


#### *PostgreSQL*
En √©l se crean dos bases de datos, *airflow_db* y *data_db*. En la primera se encuentran elementos de *Airflow* y en la segunda es donde se volcar√°n los datos. En el *docker-compose.yml* se puede observar c√≥mo se han realizado la creaci√≥n de las tablas y de los usuarios.

Entre las caracter√≠sticas principales se puede ver que, al levantar el contenedor, se realizan comprobaciones de que existan las bases de datos anteriormente y, en caso negativo, las crea, **para as√≠ no machacar lo que ya existe cada vez que se levanten los contenedores**. Los datos de la base de datos **persisten aunque se bajen los contenedores**.

A la hora de insertar los datos, se realizan comprobaciones en los *DAGs*, para que en caso de que un *item* exista en la base de datos, se pueda no introducir este y continuar introduciendo el resto.

El tema de la conexi√≥n con la base de datos fue el mayor problema, posiblemente el que retras√≥ m√°s el proyecto. Esto es debido a que no pod√≠a conectarme a la base de datos, intentaba dejar por defecto unas credenciales de conexi√≥n, pero no se quedaban guardadas. Entonces, a ra√≠z de esto, vi que era a causa de problemas con los permisos, por lo que tuve que cambiar muchas partes y volver a probar todo. Tambi√©n han habido problemas relacionados con la configuraci√≥n de visores de la base de datos. No se ha podido indicar concretamente una conexi√≥n para dejarla por defecto y que no haya que ponerla a mano. Aun as√≠, en */docker/* se muestra un TXT con las credenciales, por si se quiere introducir a mano. 


#### *PgAdmin*
Se ha creado un contenedor con la aplicaci√≥n web *PgAdmin* para poder visualizar los datos y tener un mejor control de la base de datos. No se ha podido sacarle mucha m√°s utilidad que visualizar los datos, ya que no se ha podido implementar algunas ideas que se ten√≠an para la base de datos, como triggers.

Se puede acceder a el a trav√©s del navegador con:
```
http://localhost:5050/
```

#### *Airflow*
Se han creado 4 ***DAGs***:
* 01: Comprobaci√≥n de contenedores y de datos existentes.
* 02: Generar los datos con *Kedro* usando *kedro run.*
* 03: Inserci√≥n de los datos en la base de datos.
* 04: Borrado completo de los datos en la base de datos *(extra, para pruebas y visualizaci√≥n de funcionamiento de partes)*.

Como se ha dicho ya, se buscaba separar funcionalidades y la parte de los datos los genera *Kedro*. La parte de volcado, al ser m√°s general, se ha decidido que se realice a trav√©s de un *DAG*, ya que esta tarea no corresponde a un flujo de datos como se realiza en *Kedro*. Adem√°s, as√≠ se demuestra un mayor conocimiento de los *DAGs*. Tambi√©n, se han a√±adido funciones de control de errores para saber qu√© ha estado fallando, revisando para ello los *logs* en la web (aqu√≠ la decisi√≥n de documentar bien las salidas en la parte de *Kedro*, entre otros). Los *DAGs* se encuentan en la carpeta */DAGs* y funcionan de forma s√≠ncrona con el volumen. Todo cambio en esta carpeta se refleja en el volumen del contenedor.

En relaci√≥n a los problemas, el mayor nuevamente ha sido los permisos. **Soy consciente de que es una mala pr√°ctica** que el usuario *root* sea el usuario por defecto de este contenedor, pero nuevamente, tuve mucho problema con los permisos. Puedo lograr que *Airflow* tenga su usuario por defecto, pero cuando lo logro, obtengo problemas con el grupo *Docker* y se me presentan problemas al acceder al *socket*, impidi√©ndome la comunicaci√≥n entre contenedores e incluso la ejecuci√≥n. Creo que el problema es c√≥mo creo estos usuarios en el *docker-compose* e incluso en c√≥mo se registra la informaci√≥n de *Airflow* en la base de datos.

#### *Docker*
Hay varios contenedores de *Docker*, indicados en el fichero *docker-compose.yml*. Se ha decidido incorporar tambi√©n *Kedro* en un entorno propio ya que este tipo de *framework* se utiliza en √°reas con muchas librer√≠as pesadas, como *Scikit-Learn* o *PyTorch*, entre otras. El levantamiento de todos los contenedores se logra √∫nicamente con *docker-compose.yml*, ah√≠ se puede ver reflejado c√≥mo se han montado los vol√∫menes, buscando todo el rato una correcta forma de tratarlos. **Ten√≠a claras dos cosas desde el inicio del desarrollo**, una era que el contenido de *Kedro* se sincronizara entre el contenedor y el repositorio local y la otra que el contenido de la base de datos no se perdiera tras cerrar los contenedores. Hasta donde me ha permitido el tiempo probar, esto se cumple.
Se ha creado una imagen de Kedro propia, ya que este no dispone de una imagen en Docker Hub, por lo que se ha creado un *Dockerfile* para ello. **No es necesario construir la imagen**, la imagen est√° subida a *Docker Hub* y se descarga de forma autom√°tica la primera vez que se lanzan los contenedores en una m√°quina nueva.

Nuevamente, el tema de los permisos ha sido un problema, y es a ra√≠z de este fichero. Tambi√©n, s√© que hay partes que quiz√° podr√≠an estar un poco mejor hechas, pero que tuve que dejar as√≠ dado que me estaba retrasando demasiado y no hab√≠a avanzado en otras.

Otro problema relacionado con *Docker* y por el cual perd√≠ un d√≠a entero fue por el tema de la virtualizaci√≥n. *Docker* utiliza en *Windows* una virtualizaci√≥n llamada *Hyper-V* junto con el subsistema de *Linux* para *Windows*, en concreto el 2, y ambas de estas tecnolog√≠as **no funcionan en mi ordenador personal ni en un port√°til que me prestaron**. Tuve que crear una m√°quina virtual de *Linux* y ah√≠ pude realizar todo. Para probar el proyecto en *Windows* prob√© a crear una m√°quina virtual, pero tras instalar *Docker* en ella no me dejaba iniciar *Windows*. El problema era nuevamente por *Hyper-V*. Es por esto que **no he podido probar al completo el proyecto en un entorno Windows**.

He intentado tener cuidado con c√≥mo atribuyo permisos y usado scripts de *bash*, para que se ejecuten estos en los contenedores y que as√≠ no haya problema con *Windows*, pero aun as√≠ las rutas de los vol√∫menes est√°n en formato *Linux* y no din√°micas, dado que no he podido hacer pruebas. Aun as√≠, y hasta donde le√≠ en la documentaci√≥n, *Docker Desktop* se encarga de esto √∫ltimo, pero no tengo forma de probarlo.


## üí°  Cosas que quer√≠a implementar

Dada la falta de tiempo, sobre todo perdido por problemas relacionados con mi *hardware* y problemas con los permisos, no he podido realizar muchas de las cosas que me gustar√≠a.  En los objetivos comento ideas que ten√≠a en mente durante el desarrollo. Prefer√≠ priorizar estas ya que considero que son muy importantes, pero por tiempo se quedaron fuera otras.

‚ùå La lista principal de cosas que no se han podido implementar es:

* A√±adir nodos en Kedro (funciones) para mostrar un mejor uso de Kedro y de sus pipelines.
* Integraci√≥n de pruebas unitarias en Kedro, permitiendo mejorar el tratamiento de los datos y de futuras ampliaciones.
* Mejor uso de los permisos, en concreto, del contenedor de Airflow.
* Uso de restricciones y triggers de auditor√≠a, seguridad, dominio, integridad y extensi√≥n en la base de datos.
* DAGs adicionales, en concreto para los nuevos procesos de Kedro.
* Dependencias entre DAGs y mostrar el potencial de uso de Airflow teniendo varios DAGs.
* Herramienta personalizada para visualizar los datos en navegador, formato dashboard.
* Capa de seguridad de cara al manejo de contrase√±as y c√≥mo quedan reflejadas en el *docker-compose.yml*.
* Pruebas unitarias para cada parte, para demostrar el correcto funcionamiento de forma r√°pida.
* Diagrama profesional con el funcionamiento del proyecto. Diviendo sus partes y mostrando como se comunica todo.

Muchas de estas partes son relativamente f√°ciles de a√±adir, ya que se plane√≥ todo teniendo esto en mente.  
Otras, como las herramientas, podr√≠an haber sido un poco m√°s dif√≠ciles de implementar. Aun as√≠, creo que a pesar de los imprevistos, he logrado realizar lo esencial, intentando seguir buenos m√©todos y aprendiendo c√≥mo funciona cada componente.
